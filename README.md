# **AI Summary Generator**

This tool processes URLs for online articles and generates an accurate breakdown of the contents. It also generates a visual for the article using DALLE. The summary and visual are generated through the use of Large Language Models (LLMs) and natural language processing techniques, allowing for quick and accurate analysis of online articles. This README itself was written by an LLM.

## **Getting Started**

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes.

### **Prerequisites**

- Docker
- OpenAI API key
- DeepL API key

### **Installing**

To install the project, follow these steps:

1. Clone the repository:

```bash
git clone https://github.com/0xmrwn/automated-news-breakdown.git
```

2. Create a **`.env`** file in the root directory of the project and add your API keys:

```tsx
OPENAI_API_KEY=<your-openai-api-key>
DEEPL_API_KEY=<your-deepl-api-key>
```

3. Build the Docker image:

```bash
docker build -t auto-summary .
```

4. Run the Docker container:

```bash
docker run -p 8080:8080 auto-summary
```

This will start the gunicorn server and expose it on port 8080.

## **Using the API**

The Flask server has a single endpoint, **`/process_url`**, which accepts a POST request with a URL in the form data. The function uses this URL to extract an article and then uses the OpenAI API to generate a title, summary, and set of instructions for image generation. These instructions are used to generate an image with DALLE, and the DeepL API is used to translate the title and summary to a target language specified in the configuration. Finally, the function builds and returns an HTML object with the translated title, summary, image, and instructions.

To test the API, you can send a POST request to the **`/process_url`** endpoint with a URL in the form data. The following command will send the request and open a browser to display the resulting HTML:

```bash
curl -X POST -d "url=<your-url>" http://localhost:8080/process_url | xargs open
```

## **Configuration**

The configuration file, **`config.yml`**, contains the following parameters:

- **`version`**: the version number of the configuration file
- **`translation_target`**: the target language for DeepL translations (two-letter language code)
- **`goose_config`**: configuration options for the **`goose3`** library used for article scraping.
  - **`browser_user_agent`**: Specifies the user agent string of the web browser used by Goose when scraping the article.
  - **`enable_image_fetching`**: Determines whether or not Goose should download images when scraping the article.
  - **`keep_footnotes`**: Controls whether or not footnotes are included in the scraped article text.
  - **`parse_headers`**: Determines whether or not Goose should parse headers in the article to improve the extraction of the main article text.
  - **`strict`**: Controls the strictness of Goose's article extraction process. When set to **`True`**, Goose will be more strict and may exclude more content from the scraped article, but it may also be more accurate.
- **`openai_config`**: configuration options for the OpenAI API
  - **`image_size`**: the dimensions of the image generated by DALLE (formatted as **`"widthxheight"`**)
  - **`completions_engine`**: the OpenAI model to use for text completions
  - **`prompts`**: configuration options for the prompts used to generate completions
    - **`prompt`**: the prompt template with a placeholder for context
    - **`max_tokens`**: the maximum number of tokens to be generated
    - **`temperature`**: the temperature to use for token generation

## **Licensing**

This project is licensed under the MIT License - see the **LICENSE** file for details.
